--- evoformer_atten.py	2024-03-27 10:35:50.672707240 +0800
+++ evoformer_atten_patched.py	2024-03-27 11:07:47.472614118 +0800
@@ -1,10 +1,12 @@
 # Copyright (c) Microsoft Corporation.
 # SPDX-License-Identifier: Apache-2.0
+from typing import List
 
 # DeepSpeed Team
 
 from .builder import CUDAOpBuilder, installed_cuda_version
 import os
+import sys
 
 
 class EvoformerAttnBuilder(CUDAOpBuilder):
@@ -29,17 +31,20 @@
         src_dir = 'csrc/deepspeed4science/evoformer_attn'
         return [f'{src_dir}/attention.cpp', f'{src_dir}/attention_back.cu', f'{src_dir}/attention_cu.cu']
 
+    def filter_ccs(self, ccs: List[str]):
+        """
+        Prune any compute capabilities that are not compatible with the builder. Should log
+        which CCs have been pruned.
+        """
+        return [cc for cc in ccs if int(cc.split('.')[0]) >= 7]
+
     def nvcc_args(self):
-        args = super().nvcc_args()
-        try:
-            import torch
-        except ImportError:
-            self.warning("Please install torch if trying to pre-compile kernels")
-            return args
-        major = torch.cuda.get_device_properties(0).major  #ignore-cuda
-        minor = torch.cuda.get_device_properties(0).minor  #ignore-cuda
-        args.append(f"-DGPU_ARCH={major}{minor}")
-        return args
+        nvcc_flags = ['-O3'] + self.version_dependent_macros()
+        if not self.is_rocm_pytorch():
+            nvcc_flags.extend(
+                ['-allow-unsupported-compiler' if sys.platform == "win32" else '', '-lineinfo', '--use_fast_math'] +
+                self.compute_capability_args())
+        return nvcc_flags
 
     def is_compatible(self, verbose=True):
         try:
@@ -55,13 +60,9 @@
                 self.warning("Please use CUTLASS version >= 3.1.0")
                 return False
         cuda_okay = True
-        if not self.is_rocm_pytorch() and torch.cuda.is_available():  #ignore-cuda
+        if not self.is_rocm_pytorch() and torch.cuda.is_available():  # ignore-cuda
             sys_cuda_major, _ = installed_cuda_version()
             torch_cuda_major = int(torch.version.cuda.split('.')[0])
-            cuda_capability = torch.cuda.get_device_properties(0).major  #ignore-cuda
-            if cuda_capability < 7:
-                self.warning("Please use a GPU with compute capability >= 7.0")
-                cuda_okay = False
             if torch_cuda_major < 11 or sys_cuda_major < 11:
                 self.warning("Please use CUDA 11+")
                 cuda_okay = False
@@ -69,4 +70,4 @@
 
     def include_paths(self):
         includes = [f'{self.cutlass_path}/include', f'{self.cutlass_path}/tools/util/include']
-        return includes
\ No newline at end of file
+        return includes
