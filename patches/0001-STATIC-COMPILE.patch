diff --git a/deepspeed/env_report.py b/deepspeed/env_report.py
index 20932d31..fe1a4ddb 100644
--- a/deepspeed/env_report.py
+++ b/deepspeed/env_report.py
@@ -52,7 +52,7 @@ def op_report(verbose=True):
         dots = "." * (max_dots - len(op_name))
         is_compatible = OKAY if builder.is_compatible(verbose) else no
         is_installed = installed if installed_ops.get(op_name,
-                                                      False) and accelerator_name == get_accelerator()._name else no
+                                                      False) and get_accelerator()._name in accelerator_name else no
         dots2 = '.' * ((len(h[1]) + (max_dots2 - len(h[1]))) - (len(is_installed) - color_len))
         print(op_name, dots, is_installed, dots2, is_compatible)
     print("-" * (max_dots + max_dots2 + len(h[0]) + len(h[1])))
diff --git a/deepspeed/ops/adam/zenflow_torch_adam.py b/deepspeed/ops/adam/zenflow_torch_adam.py
index e3b41510..b1b972cc 100644
--- a/deepspeed/ops/adam/zenflow_torch_adam.py
+++ b/deepspeed/ops/adam/zenflow_torch_adam.py
@@ -10,7 +10,7 @@ from torch import Tensor
 from deepspeed.utils.torch import required_torch_version
 
 # Check if we have PyTorch >= 2.0 for ZenFlow features
-_ZENFLOW_AVAILABLE = required_torch_version(min_version=2.1)
+_ZENFLOW_AVAILABLE = required_torch_version(min_version=2.4)
 
 if _ZENFLOW_AVAILABLE:
     try:
diff --git a/op_builder/async_io.py b/op_builder/async_io.py
index f59cc681..68ad543d 100644
--- a/op_builder/async_io.py
+++ b/op_builder/async_io.py
@@ -66,10 +66,10 @@ class AsyncIOBuilder(TorchCPUOpBuilder):
         import torch.utils.cpp_extension
         CUDA_HOME = torch.utils.cpp_extension.CUDA_HOME
         if CUDA_HOME is None:
-            ldflags = ['-laio']  # the ROCM case
+            ldflags = ['-Wl,-Bstatic', '-laio', '-Wl,-Bdynamic']  # the ROCM case
         else:
             CUDA_LIB64 = os.path.join(CUDA_HOME, "lib64")
-            ldflags = [f'-L{CUDA_HOME}', f'-L{CUDA_LIB64}', '-laio', '-lcuda', '-lcudart']
+            ldflags = [f'-L{CUDA_HOME}', f'-L{CUDA_LIB64}', '-Wl,-Bstatic', '-laio', '-Wl,-Bdynamic', '-lcuda', '-lcudart']
         return ldflags
 
     def check_for_libaio_pkg(self):
diff --git a/op_builder/builder.py b/op_builder/builder.py
index 6eed2efc..648cacaa 100644
--- a/op_builder/builder.py
+++ b/op_builder/builder.py
@@ -524,7 +524,7 @@ class OpBuilder(ABC):
 
         from deepspeed.git_version_info import installed_ops, torch_info, accelerator_name
         from deepspeed.accelerator import get_accelerator
-        if installed_ops.get(self.name, False) and accelerator_name == get_accelerator()._name:
+        if installed_ops.get(self.name, False) and get_accelerator()._name in accelerator_name:
             # Ensure the op we're about to load was compiled with the same
             # torch/cuda versions we are currently using at runtime.
             self.validate_torch_version(torch_info)
diff --git a/op_builder/comm.py b/op_builder/comm.py
new file mode 100644
index 00000000..9a5a93ee
--- /dev/null
+++ b/op_builder/comm.py
@@ -0,0 +1,70 @@
+# Copyright (c) Microsoft Corporation.
+# SPDX-License-Identifier: Apache-2.0
+
+# DeepSpeed Team
+
+import os
+from .builder import TorchCPUOpBuilder
+
+
+class CCLCommBuilder(TorchCPUOpBuilder):
+    BUILD_VAR = "DS_BUILD_CCL_COMM"
+    NAME = "deepspeed_ccl_comm"
+
+    def __init__(self, name=None):
+        name = self.NAME if name is None else name
+        super().__init__(name=name)
+
+    def absolute_name(self):
+        return f'deepspeed.ops.comm.{self.NAME}_op'
+
+    def sources(self):
+        return ['csrc/cpu/comm/ccl.cpp', 'csrc/cpu/comm/shm.cpp']
+
+    def include_paths(self):
+        includes = ['csrc/cpu/includes']
+        return includes
+
+    def cxx_args(self):
+        return ['-O2', '-fopenmp']
+
+    def is_compatible(self, verbose=False):
+        # TODO: add soft compatibility check for private binary release.
+        #  a soft check, as in we know it can be trivially changed.
+        return super().is_compatible(verbose)
+
+    def extra_ldflags(self):
+        ccl_root_path = os.environ.get("CCL_ROOT")
+        if ccl_root_path is None:
+            raise ValueError(
+                "Didn't find CCL_ROOT, install oneCCL from https://github.com/oneapi-src/oneCCL and source its environment variable"
+            )
+        else:
+            return ['-Wl,-Bstatic', '-lccl', '-Wl,-Bdynamic', f'-L{ccl_root_path}/lib']
+
+
+class ShareMemCommBuilder(TorchCPUOpBuilder):
+    BUILD_VAR = "DS_BUILD_SHM_COMM"
+    NAME = "deepspeed_shm_comm"
+
+    def __init__(self, name=None):
+        name = self.NAME if name is None else name
+        super().__init__(name=name)
+
+    def absolute_name(self):
+        return f'deepspeed.ops.comm.{self.NAME}_op'
+
+    def sources(self):
+        return ['csrc/cpu/comm/shm_interface.cpp', 'csrc/cpu/comm/shm.cpp']
+
+    def include_paths(self):
+        includes = ['csrc/cpu/includes']
+        return includes
+
+    def cxx_args(self):
+        return ['-O2', '-fopenmp']
+
+    def is_compatible(self, verbose=False):
+        # TODO: add soft compatibility check for private binary release.
+        #  a soft check, as in we know it can be trivially changed.
+        return super().is_compatible(verbose)
diff --git a/op_builder/cpu/async_io.py b/op_builder/cpu/async_io.py
index dcb9feab..5f4a7130 100644
--- a/op_builder/cpu/async_io.py
+++ b/op_builder/cpu/async_io.py
@@ -48,7 +48,7 @@ class AsyncIOBuilder(CPUOpBuilder):
         return args
 
     def extra_ldflags(self):
-        return ['-laio', '-fopenmp']
+        return ['-Wl,-Bstatic', '-laio', '-Wl,-Bdynamic', '-fopenmp']
 
     def check_for_libaio_pkg(self):
         libs = dict(
diff --git a/op_builder/cpu/comm.py b/op_builder/cpu/comm.py
index 8f5a35d0..f818b3f6 100644
--- a/op_builder/cpu/comm.py
+++ b/op_builder/cpu/comm.py
@@ -40,7 +40,7 @@ class CCLCommBuilder(CPUOpBuilder):
                 "Didn't find CCL_ROOT, install oneCCL from https://github.com/oneapi-src/oneCCL and source its environment variable"
             )
         else:
-            return ['-lccl', f'-L{ccl_root_path}/lib']
+            return ['-Wl,-Bstatic', '-lccl', '-Wl,-Bdynamic', f'-L{ccl_root_path}/lib']
 
 
 class ShareMemCommBuilder(CPUOpBuilder):
diff --git a/op_builder/xpu/builder.py b/op_builder/xpu/builder.py
index 81b15f19..ea40d12b 100644
--- a/op_builder/xpu/builder.py
+++ b/op_builder/xpu/builder.py
@@ -76,7 +76,7 @@ class SYCLOpBuilder(OpBuilder):
     def load(self, verbose=True):
         from deepspeed.git_version_info import installed_ops, torch_info, accelerator_name  # noqa: F401
         from deepspeed.accelerator import get_accelerator
-        if installed_ops.get(self.name, False) and accelerator_name == get_accelerator()._name:
+        if installed_ops.get(self.name, False) and get_accelerator()._name in accelerator_name:
             return importlib.import_module(self.absolute_name())
         else:
             return self.jit_load(verbose)
diff --git a/setup.py b/setup.py
index 12e65dd0..20882971 100755
--- a/setup.py
+++ b/setup.py
@@ -287,7 +287,7 @@ with open('deepspeed/git_version_info_installed.py', 'w') as fd:
     fd.write(f"git_hash='{git_hash}'\n")
     fd.write(f"git_branch='{git_branch}'\n")
     fd.write(f"installed_ops={install_ops}\n")
-    fd.write(f"accelerator_name='{accelerator_name}'\n")
+    fd.write(f"accelerator_name={{'{accelerator_name}', 'cpu'}}\n")
     fd.write(f"torch_info={torch_info}\n")
 
 print(f'install_requires={install_requires}')
