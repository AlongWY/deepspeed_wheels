# This workflow will:
# - Create a new Github release
# - Build wheels for supported architectures
# - Deploy the wheels to the Github release
# - Release the static code to PyPi
# For more information see: https://help.github.com/en/actions/language-and-framework-guides/using-python-with-github-actions#publishing-to-package-registries

name: Build wheels and deploy

permissions:
  contents: write

on:
  push:
    tags:
      - v*

jobs:
  build_wheels:
    name: Build Wheel
    runs-on: ${{ matrix.os }}

    strategy:
      fail-fast: false
      matrix:
          # Using ubuntu-20.04 instead of 22.04 for more compatibility (glibc). Ideally we'd use the
          # manylinux docker image, but I haven't figured out how to install CUDA on manylinux.
          os: [ubuntu-20.04]
          python-version: ['3.7', '3.8', '3.9', '3.10', '3.11']
          torch-version: ['1.12.1', '1.13.1', '2.0.1', '2.1.2', '2.2.0']
          cuda-version: ['11.8.0', '12.2.2']
          exclude:
            # see https://github.com/pytorch/pytorch/blob/main/RELEASE.md#release-compatibility-matrix
            # Pytorch <= 1.12 does not support Python 3.11
            - torch-version: '1.12.1'
              python-version: '3.11'
            # Pytorch >= 2.0 only supports Python >= 3.8
            - torch-version: '2.0.1'
              python-version: '3.7'
            - torch-version: '2.1.2'
              python-version: '3.7'
            - torch-version: '2.2.0'
              python-version: '3.7'
            - torch-version: '2.3.0.dev20240105'
              python-version: '3.7'
            # Pytorch <= 2.0 only supports CUDA <= 11.8
            - torch-version: '1.12.1'
              cuda-version: '12.2.2'
            - torch-version: '1.13.1'
              cuda-version: '12.2.2'
            - torch-version: '2.0.1'
              cuda-version: '12.2.2'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          repository: microsoft/DeepSpeed
          ref: ${{ github.ref_name }}

      - name: Checkout cutlass repo
        uses: actions/checkout@v4
        with:
          repository: NVIDIA/cutlass
          ref: v3.4.1
          path: cutlass

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Set CUDA and PyTorch versions
        run: |
          echo "MATRIX_CUDA_VERSION=$(echo ${{ matrix.cuda-version }} | awk -F \. {'print $1 $2'})" >> $GITHUB_ENV
          echo "MATRIX_TORCH_VERSION=$(echo ${{ matrix.torch-version }} | awk -F \. {'print $1 "." $2'})" >> $GITHUB_ENV
          echo "MATRIX_PYTHON_VERSION=$(echo ${{ matrix.python-version }} | awk -F \. {'print $1 $2'})" >> $GITHUB_ENV

      - name: Free up disk space
        if: ${{ runner.os == 'Linux' }}
        # https://github.com/easimon/maximize-build-space/blob/master/action.yml
        # https://github.com/easimon/maximize-build-space/tree/test-report
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf /opt/hostedtoolcache/CodeQL

      - name: Set up swap space
        if: runner.os == 'Linux'
        uses: pierotofy/set-swap-space@v1.0
        with:
          swap-size-gb: 10

      - name: Install CUDA ${{ matrix.cuda-version }}
        if: ${{ matrix.cuda-version != 'cpu' }}
        uses: Jimver/cuda-toolkit@v0.2.14
        id: cuda-toolkit
        with:
          cuda: ${{ matrix.cuda-version }}
          method: 'network'
          sub-packages: '["toolkit"]'

      - name: Install PyTorch ${{ matrix.torch-version }}+cu${{ matrix.cuda-version }}
        run: |
          pip install --upgrade pip
          # If we don't install before installing Pytorch, we get error for torch 2.0.1
          # ERROR: Could not find a version that satisfies the requirement setuptools>=40.8.0 (from versions: none)
          pip install lit
          # We want to figure out the CUDA version to download pytorch
          # e.g. we can have system CUDA version being 11.7 but if torch==1.12 then we need to download the wheel from cu116
          # see https://github.com/pytorch/pytorch/blob/main/RELEASE.md#release-compatibility-matrix
          # This code is ugly, maybe there's a better way to do this.
          export TORCH_CUDA_VERSION=$(python -c "from os import environ as env; \
            minv = {'1.12': 113, '1.13': 116, '2.0': 117, '2.1': 118, '2.2': 118, '2.3': 118}[env['MATRIX_TORCH_VERSION']]; \
            maxv = {'1.12': 116, '1.13': 117, '2.0': 118, '2.1': 121, '2.2': 121, '2.3': 121}[env['MATRIX_TORCH_VERSION']]; \
            print(max(min(int(env['MATRIX_CUDA_VERSION']), maxv), minv))" \
          )
          if [[ ${{ matrix.torch-version }} == *"dev"* ]]; then
            if [[ ${MATRIX_TORCH_VERSION} == "2.2" ]]; then
              # --no-deps because we can't install old versions of pytorch-triton
              pip install typing-extensions jinja2
              pip install --no-cache-dir --no-deps --pre https://download.pytorch.org/whl/nightly/cu${TORCH_CUDA_VERSION}/torch-${{ matrix.torch-version }}%2Bcu${TORCH_CUDA_VERSION}-cp${MATRIX_PYTHON_VERSION}-cp${MATRIX_PYTHON_VERSION}-linux_x86_64.whl
            else
              pip install --no-cache-dir --pre torch==${{ matrix.torch-version }} --index-url https://download.pytorch.org/whl/nightly/cu${TORCH_CUDA_VERSION}
            fi
          else
            pip install --no-cache-dir torch==${{ matrix.torch-version }} --index-url https://download.pytorch.org/whl/cu${TORCH_CUDA_VERSION}
          fi
          nvcc --version
          python --version
          python -c "import torch; print('PyTorch:', torch.__version__)"
          python -c "import torch; print('CUDA:', torch.version.cuda)"
          python -c "from torch.utils import cpp_extension; print (cpp_extension.CUDA_HOME)"
        shell:
          bash

      - name: Build wheel
        run: |
          sudo apt-get -y install libaio-dev
          pip install setuptools==68.0.0 wheel
          pip install hjson ninja numpy packaging psutil py-cpuinfo  pydantic pynvml tqdm libaio deepspeed-kernels triton
          export PATH=/usr/local/nvidia/bin:/usr/local/nvidia/lib64:$PATH
          export LD_LIBRARY_PATH=/usr/local/nvidia/lib64:/usr/local/cuda/lib64:$LD_LIBRARY_PATH
          export CUTLASS_PATH=$(pwd)/cutlass
          MAX_JOBS=2 TORCH_CUDA_ARCH_LIST="6.1;7.0;7.5;8.0;8.6;8.9;9.0" DS_BUILD_OPS=1 DS_BUILD_SPARSE_ATTN=0 DS_BUILD_EVOFORMER_ATTN=0 python setup.py build_ext -j2 bdist_wheel --dist-dir=dist
          tmpname=cu${MATRIX_CUDA_VERSION}torch${MATRIX_TORCH_VERSION}
          wheel_name=$(ls dist/*whl | xargs -n 1 basename | sed "s/+\w*-/+$tmpname-/2")
          ls dist/*whl |xargs -I {} mv {} dist/${wheel_name}
          echo "wheel_name=${wheel_name}" >> $GITHUB_ENV

      - name: Log Built Wheels
        run: |
          ls dist

      - name: Upload Release Asset
        uses: softprops/action-gh-release@v2
        if: startsWith(github.ref, 'refs/tags/')
        with:
          files: |
            ./dist/${{env.wheel_name}}
